{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "This notebook contains work for the [Kaggle Titanic Competition](https://www.kaggle.com/c/titanic). From the website:\n",
    "\n",
    "> The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships.\n",
    "\n",
    "> One of the reasons that the shipwreck led to such loss of life was that there were not enough lifeboats for the passengers and crew. Although there was some element of luck involved in surviving the sinking, some groups of people were more likely to survive than others, such as women, children, and the upper-class.\n",
    "\n",
    "> In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.\n",
    "\n",
    "We will attempt to build a model predicts which passengers aboard the Titanic survived. Data sourced from https://www.kaggle.com/c/titanic/data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Set options\n",
    "from IPython.display import display\n",
    "pd.set_option('display.max_columns', 15)\n",
    "\n",
    "# Load the train and test datasets into two DataFrames\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Let's start by getting a general sense for the data that we will be dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training set has 891 observations and 12 variables.\n",
      "The training set has the following NaN values:\n",
      "PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "The testing set has 418 observations and 11 variables.\n",
      "The testing set has the following NaN values:\n",
      "PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get dimensions\n",
    "print(\"The training set has {} observations and {} variables.\".format(*train.shape))\n",
    "print(\"The training set has the following NaN values:\")\n",
    "print(train.isnull().sum())\n",
    "print(\"The testing set has {} observations and {} variables.\".format(*test.shape))\n",
    "print(\"The testing set has the following NaN values:\")\n",
    "print(test.isnull().sum())\n",
    "\n",
    "# Explore the data\n",
    "display(train.head(5))\n",
    "display(train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start with the numeric fields. The first thing we notice is that Age has plenty of `NaN` values. Since we don't want to remove the Age variable nor remove the observations with missing values, we will need to clean this up.\n",
    "\n",
    "We can use the `fillna` method on the Age series to replace any `NaN` with a value of our choice. There are plenty of different strategies to achomplish this, for our purposes we will replace the missing values with the median age. The test set also has a NaN for Fair, so let's also fix that in the same way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess: NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.361582</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>13.019697</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  891.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.361582    0.523008   \n",
       "std     257.353842    0.486592    0.836071   13.019697    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   22.000000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   35.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace NaN values in the Age variable\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].median())\n",
    "test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].median())\n",
    "test[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())\n",
    "display(train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should do it for the numeric variables, but we still need to consider the non-numeric variables:\n",
    "* `Name`\n",
    "* `Sex`\n",
    "* `Cabin`\n",
    "* `Embarked`\n",
    "* `Ticket`\n",
    "\n",
    "We can't easily feed non-numeric columns into a machine learning algorithm, so we will have to convert the ones we want to use to a dummy or categorical variable. `Name` is probably not a feature that will be useful for making predictions, so we can throw that out (it might be possible to extract titles like \"lord\" from the names which could be useful). `Cabin` appears to have many `NaN` values, so let's throw that out. `Ticket` doesn't appear to be useful without a better understanding of what the ticket numbers mean, so let's also get rid of that.\n",
    "\n",
    "`Sex` is probably important, the whole women and children first thing, so let's work on converting that to a dummy variable. Let's convert all the values of `male` to `0` and all the values of `female` to `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess: Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male' 'female']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Sex, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore Sex\n",
    "print(test[\"Sex\"].unique())\n",
    "\n",
    "# Convert male to 0\n",
    "train.loc[train[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "test.loc[test[\"Sex\"] == \"male\", \"Sex\"] = 0\n",
    "\n",
    "# Convert female to 1\n",
    "train.loc[train[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "test.loc[test[\"Sex\"] == \"female\", \"Sex\"] = 1\n",
    "\n",
    "display(train['Sex'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Embarked` is another interesting variable. It tells us which port a passenger embarked from. There are four unique values for `Embarked`:\n",
    "* `S`: Departed from Southampton.\n",
    "* `C`: Departed from Cherbourg.\n",
    "* `Q`: Departed from Queenstown.\n",
    "* `NaN`: Missing value.\n",
    "\n",
    "Since `S` is the most common port, let's replace the `NaN` values with that and then convert the three letter codes to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['S' 'C' 'Q' nan]\n",
      "S    0.724409\n",
      "C    0.188976\n",
      "Q    0.086614\n",
      "Name: Embarked, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Embarked, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore Embarked\n",
    "print(train[\"Embarked\"].unique())\n",
    "print(train[\"Embarked\"].value_counts(normalize = True))\n",
    "\n",
    "# Fill NaN values with S\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# Convert S = 0, C = 1, Q = 2\n",
    "train.loc[train[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "test.loc[test[\"Embarked\"] == \"S\", \"Embarked\"] = 0\n",
    "\n",
    "train.loc[train[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "test.loc[test[\"Embarked\"] == \"C\", \"Embarked\"] = 1\n",
    "\n",
    "train.loc[train[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "test.loc[test[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n",
    "\n",
    "display(train['Embarked'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strategize\n",
    "\n",
    "Now that our variables are cleaned up, let's look a bit closer at the data. For example, we might assume that women and children had a higher probability of survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival rate in training set: 38%\n",
      "Male survival rate in training set: 19%\n",
      "Female survival rate in training set: 74%\n",
      "Survival rate of those under 10: 61%\n"
     ]
    }
   ],
   "source": [
    "# Explore survival in training set\n",
    "print(\"Survival rate in training set: {:.0%}\".format(train[\"Survived\"].value_counts(normalize = True)[1]))\n",
    "\n",
    "# Explore survival by sex in training set\n",
    "print(\"Male survival rate in training set: {:.0%}\".format(train[\"Survived\"] \\\n",
    "                                                          [train[\"Sex\"] == 0].value_counts(normalize=True)[1]))\n",
    "print(\"Female survival rate in training set: {:.0%}\".format(train[\"Survived\"] \\\n",
    "                                                          [train[\"Sex\"] == 1].value_counts(normalize=True)[1]))\n",
    "\n",
    "# Explore survival by age in training set\n",
    "print(\"Survival rate of those under 10: {:.0%}\".format(train[\"Survived\"] \\\n",
    "                                                       [train[\"Age\"] < 10].value_counts(normalize=True)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also create some of our own features. For example we can create a variable that tells us whether or not a passenger is a child (`Age < 10`) or how many people are in a passenger's family (`SibSp` + `Parch`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the variable Child and assign to 'NaN'\n",
    "train[\"Child\"] = float('NaN')\n",
    "test[\"Child\"] = float('NaN')\n",
    "\n",
    "# Assign 1 to passengers under 10, 0 to those 12 or older.\n",
    "train.loc[train[\"Age\"] < 10, \"Child\"] = 1\n",
    "train.loc[train[\"Age\"] >= 10, \"Child\"] = 0\n",
    "test.loc[test[\"Age\"] < 10, \"Child\"] = 1\n",
    "test.loc[test[\"Age\"] >= 10, \"Child\"] = 0\n",
    "\n",
    "# Create the variable FamilySize\n",
    "train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"]\n",
    "test[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we didn't think `Name` would be very useful, but it might be able to extract the title of a passenger (Mr, Mrs, Master, etc). This could be a useful proxy for wealth and marital status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mr          517\n",
       "Miss        182\n",
       "Mrs         125\n",
       "Master       40\n",
       "Dr            7\n",
       "Rev           6\n",
       "Major         2\n",
       "Mlle          2\n",
       "Col           2\n",
       "Countess      1\n",
       "Lady          1\n",
       "Capt          1\n",
       "Mme           1\n",
       "Don           1\n",
       "Sir           1\n",
       "Ms            1\n",
       "Jonkheer      1\n",
       "Name: Name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1     517\n",
       "2     183\n",
       "3     125\n",
       "4      40\n",
       "5       7\n",
       "6       6\n",
       "7       5\n",
       "10      3\n",
       "8       3\n",
       "9       2\n",
       "Name: Name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import regular expression library\n",
    "import re\n",
    "\n",
    "# Build function to get titles\n",
    "def get_title(name):\n",
    "    # Titles always consist of capital and lowercase letters, and end with a period.\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    # If the title exists, extract and return it.\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "# Get all the titles and print how often each one occurs.\n",
    "titles = train[\"Name\"].apply(get_title)\n",
    "test_titles = test[\"Name\"].apply(get_title)\n",
    "display(pd.value_counts(titles))\n",
    "\n",
    "# Map each title to an integer.  Some titles are very rare, and are compressed into the same codes as other titles.\n",
    "title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Dr\": 5, \"Rev\": 6, \"Major\": 7,\n",
    "                 \"Col\": 7, \"Mlle\": 8, \"Mme\": 8, \"Don\": 9, \"Lady\": 10, \"Countess\": 10,\n",
    "                 \"Jonkheer\": 10, \"Sir\": 9, \"Capt\": 7, \"Ms\": 2, \"Dona\": 10}\n",
    "for k,v in title_mapping.items():\n",
    "    titles[titles == k] = v\n",
    "    test_titles[test_titles == k] = v\n",
    "\n",
    "# Verify that we converted everything.\n",
    "display(pd.value_counts(titles))\n",
    "\n",
    "# Add in the title column.\n",
    "train[\"Title\"] = titles\n",
    "test[\"Title\"] = test_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going even further, we might be able to combine `FamilySize` and a person's last name to determine which family a person belongs too. Giving each family a unique id could be a useful feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1      800\n",
       " 14       8\n",
       " 149      7\n",
       " 63       6\n",
       " 50       6\n",
       " 59       6\n",
       " 17       5\n",
       " 384      4\n",
       " 27       4\n",
       " 25       4\n",
       " 162      4\n",
       " 8        4\n",
       " 84       4\n",
       " 340      4\n",
       " 43       3\n",
       " 269      3\n",
       " 58       3\n",
       " 633      2\n",
       " 167      2\n",
       " 280      2\n",
       " 510      2\n",
       " 90       2\n",
       " 83       1\n",
       " 625      1\n",
       " 376      1\n",
       " 449      1\n",
       " 498      1\n",
       " 588      1\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import operator library\n",
    "import operator\n",
    "\n",
    "# Initiate dictionary mapping family name to id\n",
    "family_id_mapping = {}\n",
    "\n",
    "# Build function to get the id\n",
    "def get_family_id(row):\n",
    "    # Find the last name by splitting on a comma\n",
    "    last_name = row[\"Name\"].split(\",\")[0]\n",
    "    # Create the family id\n",
    "    family_id = \"{0}{1}\".format(last_name, row[\"FamilySize\"])\n",
    "    # Look up the id in the mapping\n",
    "    if family_id not in family_id_mapping:\n",
    "        if len(family_id_mapping) == 0:\n",
    "            current_id = 1\n",
    "        else:\n",
    "            # Get the maximum id from the mapping and add one to it if we don't have an id\n",
    "            current_id = (max(family_id_mapping.items(), key=operator.itemgetter(1))[1] + 1)\n",
    "        family_id_mapping[family_id] = current_id\n",
    "    return family_id_mapping[family_id]\n",
    "\n",
    "# Get the family ids with the apply method\n",
    "family_ids = train.apply(get_family_id, axis=1)\n",
    "test_family_ids = test.apply(get_family_id, axis=1)\n",
    "\n",
    "# There are a lot of family ids, so we'll compress all of the families under 3 members into one code.\n",
    "family_ids[train[\"FamilySize\"] < 3] = -1\n",
    "test_family_ids[test[\"FamilySize\"] < 3] = -1\n",
    "\n",
    "# Print the count of each unique id.\n",
    "display(pd.value_counts(family_ids))\n",
    "\n",
    "train[\"FamilyId\"] = family_ids\n",
    "test[\"FamilyId\"] = test_family_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see if we can create a variable that tells us whether the passenger is a mother or not. It could be argued that a mother with her child would have a higher probability of making it to a lifeboat. To filter for mothers, I will select:\n",
    "* `Sex = 1` (Female)\n",
    "* `Age > 18`\n",
    "* `Parch > 0`\n",
    "* `Title != 2` (Miss)\n",
    "\n",
    "Mothers will be labeled 1 and not mothers will be labeled 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the variable Mother and assign to 'NaN'\n",
    "train[\"Mother\"] = 0\n",
    "test[\"Mother\"] = 0\n",
    "\n",
    "# Assign 1 to mothers, 0 to non-mothers.\n",
    "train.loc[(train[\"Sex\"] == 1) & (train[\"Age\"] > 18) & (train[\"Parch\"] > 1) & (test[\"Title\"] != 2), \"Mother\"] = 1\n",
    "test.loc[(test[\"Sex\"] == 1) & (test[\"Age\"] > 18) & (test[\"Parch\"] > 1) & (test[\"Title\"] != 2), \"Mother\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metric\n",
    "Before we begin building our model, we will need to specify our evaluation metric. From the Kaggle competition description, the error metric is simply the percentage of correct predictions.\n",
    "\n",
    "```\n",
    "accuracy = sum(predictions[predictions == titanic[\"Survived\"]]) / len(predictions)\n",
    "```\n",
    "\n",
    "Since we'll be using GridSearchCV to optimize our classifier, let's pick a more robust evaluation metric for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import evaluation libraries\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from time import time\n",
    "\n",
    "# Build scorer for GridSearch\n",
    "scorer = make_scorer(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model: Random Forest\n",
    "We will be using a random forest classifier to model survival. With RandomForests, a diverse set of classifiers is created by introducing randomness in the classifier construction. It fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting.\n",
    "\n",
    "Decision Trees use simple decision rules inferred from the data to predict the value of the target variable. This makes sense for our case since we can imagine some of these simple rules ourselves. For example, if age is less than 10 or if the passenger is female, we could predict survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best parameters are {'criterion': 'entropy', 'max_depth': 24, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 15, 'n_estimators': 100} with a score of 77%\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize predictors, features, and labels\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\",\n",
    "              \"FamilySize\", \"Child\", \"Title\", \"FamilyId\", \"Mother\"]\n",
    "features = train[predictors]\n",
    "labels = train[\"Survived\"]\n",
    "\n",
    "# Initialize classifier and parameters\n",
    "clf = RandomForestClassifier()\n",
    "params = {\"n_estimators\": [50, 100, 150],\n",
    "          \"criterion\": ['gini', 'entropy'],\n",
    "          \"max_features\": [None, 'auto'],\n",
    "          \"max_depth\": [None, 24, 25, 26],\n",
    "          \"min_samples_split\": [10, 15, 20],\n",
    "          \"min_samples_leaf\": [1, 2, 5]}\n",
    "\n",
    "# Initialize cross validation\n",
    "cv = StratifiedShuffleSplit(n_splits=5, test_size=0.20)\n",
    "\n",
    "# Build GridSearch and fit\n",
    "clf = GridSearchCV(clf, params, scoring=scorer, cv=cv)\n",
    "clf.fit(features, labels)\n",
    "\n",
    "print(\"The best parameters are {} with a score of {:.0%}\".format(clf.best_params_, clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our optimized classifier, we can work on our submission to Kaggle. Kaggle requires a csv submission with two columns (PassengerId, Survived)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Manually create classifier\n",
    "clf = RandomForestClassifier(n_estimators=150, criterion='entropy', max_features=None,\n",
    "                             max_depth=25, min_samples_split=15, min_samples_leaf=1)\n",
    "\n",
    "# Initialize our inputs using the whole training set this time\n",
    "X_train = train[predictors]\n",
    "y_train = train[\"Survived\"]\n",
    "X_test = test[predictors]\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test set\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Create a new dataframe with only the columns Kaggle wants from the dataset\n",
    "submission = pd.DataFrame({\"PassengerId\": test[\"PassengerId\"], \n",
    "                           \"Survived\": predictions})\n",
    "\n",
    "# Export to csv\n",
    "submission.to_csv(\"data/titanic_submission_rf.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:aind]",
   "language": "python",
   "name": "conda-env-aind-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
